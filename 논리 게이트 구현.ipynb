{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4570dc57-83f4-4222-bdbf-71d7d1b697f3",
   "metadata": {},
   "source": [
    "## 논리 게이트 구현1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "467e24d6-be0e-4526-af47-835da4b028ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AND 게이트 구현 예\n",
    "def AND_gate(x1, x2):\n",
    "    w1 = 1\n",
    "    w2 = 1\n",
    "    b = -1\n",
    "    result = w1*x1 + w2*x2 + b\n",
    "\n",
    "    if result <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6566c04c-7bb1-48d8-aa4e-83ee5cd8e501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAND 게이트 구현 예\n",
    "def NAND_gate(x1, x2):\n",
    "    w1 = -0.5\n",
    "    w2 = -0.5\n",
    "    b = 1\n",
    "    result = w1*x1 + w2*x2 + b\n",
    "\n",
    "    if result <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83504e88-6cee-4f59-8a05-104fe2d0a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR 게이트 구현 예\n",
    "def OR_gate(x1, x2):\n",
    "    w1 = 1\n",
    "    w2 = 1\n",
    "    b = -0.5\n",
    "    result = w1*x1 + w2*x2 + b\n",
    "\n",
    "    if result <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b462863e-9509-4297-b400-5510ccc4dc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XOR 게이트 구현 예\n",
    "def XOR_gate(x1, x2):\n",
    "    z1 = NAND_gate(x1, x2)\n",
    "    z2 = OR_gate(x1, x2)\n",
    "    y = AND_gate(z1, z2)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0315a34-d7cd-4532-9b1f-77bc2856eb16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND gate\n",
      "(0, 0)->0\n",
      "(0, 1)->0\n",
      "(1, 0)->0\n",
      "(1, 1)->1\n"
     ]
    }
   ],
   "source": [
    "print(\"AND gate\")\n",
    "for xs in [(0, 0), (0, 1), (1, 0), (1, 1)]:\n",
    "    y = AND_gate(xs[0], xs[1])\n",
    "    print(str(xs) + \"->\" + str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f1aa319-92d0-4b24-9e13-aee9e3eddcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAND gate\n",
      "(0, 0)->1\n",
      "(0, 1)->1\n",
      "(1, 0)->1\n",
      "(1, 1)->0\n"
     ]
    }
   ],
   "source": [
    "print(\"NAND gate\")\n",
    "for xs in [(0, 0), (0, 1), (1, 0), (1, 1)]:\n",
    "    y = ＮAND_gate(xs[0], xs[1])\n",
    "    print(str(xs) + \"->\" + str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e11b5962-0b9f-4e42-931c-39961bf0c542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OR gate\n",
      "(0, 0)->0\n",
      "(0, 1)->1\n",
      "(1, 0)->1\n",
      "(1, 1)->1\n"
     ]
    }
   ],
   "source": [
    "print(\"OR gate\")\n",
    "for xs in [(0, 0), (0, 1), (1, 0), (1, 1)]:\n",
    "    y = OR_gate(xs[0], xs[1])\n",
    "    print(str(xs) + \"->\" + str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cc1db68-ebfd-430b-9fcf-f108f734549a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR gate\n",
      "(0, 0)->0\n",
      "(0, 1)->1\n",
      "(1, 0)->1\n",
      "(1, 1)->0\n"
     ]
    }
   ],
   "source": [
    "print(\"XOR gate\")\n",
    "for xs in [(0, 0), (0, 1), (1, 0), (1, 1)]:\n",
    "    y = XOR_gate(xs[0], xs[1])\n",
    "    print(str(xs) + \"->\" + str(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0999716-678c-4174-a56f-7140eda17307",
   "metadata": {},
   "source": [
    "## 논리 게이트 구현2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc3c3b33-23d2-4871-9a3a-1f730653e3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6932064294815063\n",
      "100 0.14414836466312408\n",
      "200 0.0817771703004837\n",
      "300 0.05658476799726486\n",
      "400 0.04307378828525543\n",
      "500 0.03469350188970566\n",
      "600 0.029005466029047966\n",
      "700 0.024899723008275032\n",
      "800 0.021800503134727478\n",
      "900 0.01938023790717125\n",
      "1000 0.01743890717625618\n",
      "\n",
      "\n",
      "\n",
      "hypothesis값 : \n",
      "tensor([[1.2500e-05],\n",
      "        [2.0266e-02],\n",
      "        [2.0266e-02],\n",
      "        [9.7162e-01]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "\n",
      "예측값 : \n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]])\n",
      "\n",
      "\n",
      "실제값 : \n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "# 도구 임포트\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# GPU 연산이 가능할 경우 GPU 연산 수행\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    toch.cuda.manual_seed_all(777)\n",
    "\n",
    "# 각gate문제에해당하는입력과출력정의\n",
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [0], [0], [1]]).to(device) #AND\n",
    "# Y=torch.FloatTensor([[1], [1], [1], [0]]).to(device) #NAND\n",
    "# Y=torch.FloatTensor([[0], [1], [1], [1]]).to(device) #OR\n",
    "# Y=torch.FloatTensor([[0], [1], [1], [0]]).to(device) #XOR\n",
    "\n",
    "# 단층 퍼셉트론 설계\n",
    "linear = nn.Linear(2, 1, bias=True)\n",
    "sigmoid = nn.Sigmoid()\n",
    "model = nn.Sequential(linear, sigmoid).to(device)\n",
    "\n",
    "# 이진 분류 문제이므로 비용 함수로 크로스엔트로피 함수 사용\n",
    "# nn.BCELoss() - 이진 분류에서 사용하는 크로스엔트로피 함수\n",
    "\n",
    "# 비용 함수와 옵티마이저 정의\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "#반복학습수행\n",
    "for step in range(1001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    \n",
    "    #비용함수\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    " \n",
    "    if step % 100 == 0:  # 100번째 에포크마다 비용 출력\n",
    "        print(step, cost.item())\n",
    "        \n",
    "print('\\n\\n')\n",
    "print('hypothesis값 : ')\n",
    "print(hypothesis)\n",
    "\n",
    "print('\\n')\n",
    "predicted = (hypothesis > 0.5).float()\n",
    "print('예측값 : ')\n",
    "print(predicted)\n",
    "\n",
    "print('\\n')\n",
    "print('실제값 : ')\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ca77895-1a71-4e3b-a0b0-740fb7fa193f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7434073090553284\n",
      "100 0.693165123462677\n",
      "200 0.6931577920913696\n",
      "300 0.6931517124176025\n",
      "400 0.6931463479995728\n",
      "500 0.6931411027908325\n",
      "600 0.693135678768158\n",
      "700 0.6931294798851013\n",
      "800 0.6931220889091492\n",
      "900 0.6931126117706299\n",
      "1000 0.6930999755859375\n",
      "1100 0.6930823922157288\n",
      "1200 0.6930569410324097\n",
      "1300 0.6930190920829773\n",
      "1400 0.6929606199264526\n",
      "1500 0.6928660273551941\n",
      "1600 0.6927032470703125\n",
      "1700 0.6923960447311401\n",
      "1800 0.6917301416397095\n",
      "1900 0.6899653077125549\n",
      "2000 0.6838314533233643\n",
      "2100 0.6561663150787354\n",
      "2200 0.43109801411628723\n",
      "2300 0.13489243388175964\n",
      "2400 0.06630408763885498\n",
      "2500 0.04216805472970009\n",
      "2600 0.030453797429800034\n",
      "2700 0.023665882647037506\n",
      "2800 0.01927771419286728\n",
      "2900 0.01622401550412178\n",
      "3000 0.01398373395204544\n",
      "3100 0.012273895554244518\n",
      "3200 0.010928076691925526\n",
      "3300 0.009842460043728352\n",
      "3400 0.008949019014835358\n",
      "3500 0.00820132251828909\n",
      "3600 0.007566746324300766\n",
      "3700 0.0070216478779911995\n",
      "3800 0.006548585370182991\n",
      "3900 0.006134245544672012\n",
      "4000 0.00576836708933115\n",
      "4100 0.005443031433969736\n",
      "4200 0.005151892080903053\n",
      "4300 0.004889909643679857\n",
      "4400 0.004652875475585461\n",
      "4500 0.004437455907464027\n",
      "4600 0.004240856971591711\n",
      "4700 0.004060687497258186\n",
      "4800 0.0038950243033468723\n",
      "4900 0.003742204513400793\n",
      "5000 0.0036007293965667486\n",
      "5100 0.0034694760106503963\n",
      "5200 0.003347307676449418\n",
      "5300 0.00323338620364666\n",
      "5400 0.003126882016658783\n",
      "5500 0.0030270610004663467\n",
      "5600 0.002933344803750515\n",
      "5700 0.0028451993130147457\n",
      "5800 0.002762149553745985\n",
      "5900 0.0026837813202291727\n",
      "6000 0.002609651070088148\n",
      "6100 0.002539478475227952\n",
      "6200 0.0024729501456022263\n",
      "6300 0.0024097608402371407\n",
      "6400 0.002349723828956485\n",
      "6500 0.0022925594821572304\n",
      "6600 0.002238068962469697\n",
      "6700 0.0021860888227820396\n",
      "6800 0.0021364723797887564\n",
      "6900 0.0020890086889266968\n",
      "7000 0.0020436227787286043\n",
      "7100 0.0020001279190182686\n",
      "7200 0.0019583976827561855\n",
      "7300 0.001918404595926404\n",
      "7400 0.0018799994140863419\n",
      "7500 0.0018430724740028381\n",
      "7600 0.0018075506668537855\n",
      "7700 0.0017733543645590544\n",
      "7800 0.0017404216341674328\n",
      "7900 0.0017087101005017757\n",
      "8000 0.0016780958976596594\n",
      "8100 0.0016485494561493397\n",
      "8200 0.001620007213205099\n",
      "8300 0.001592440064996481\n",
      "8400 0.0015657985350117087\n",
      "8500 0.0015400205738842487\n",
      "8600 0.0015150569379329681\n",
      "8700 0.001490917056798935\n",
      "8800 0.0014674888225272298\n",
      "8900 0.0014448154252022505\n",
      "9000 0.0014228178188204765\n",
      "9100 0.0014014793559908867\n",
      "9200 0.0013806945644319057\n",
      "9300 0.0013605987187474966\n",
      "9400 0.0013410557294264436\n",
      "9500 0.0013220261316746473\n",
      "9600 0.0013035556767135859\n",
      "9700 0.0012856305111199617\n",
      "9800 0.0012681189691647887\n",
      "9900 0.0012511077802628279\n",
      "10000 0.0012345178984105587\n",
      "\n",
      "\n",
      "\n",
      "hypothesis값 : \n",
      "tensor([[0.0011],\n",
      "        [0.9989],\n",
      "        [0.9989],\n",
      "        [0.0017]], grad_fn=<SigmoidBackward0>)\n",
      "\n",
      "\n",
      "예측값 : \n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "\n",
      "\n",
      "실제값 : \n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "# 도구 임포트\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# GPU 연산이 가능할 경우 GPU 연산 수행\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    toch.cuda.manual_seed_all(777)\n",
    "\n",
    "# 각gate문제에해당하는입력과출력정의\n",
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "#  = torch.FloatTensor([[0], [0], [0], [1]]).to(device) #AND\n",
    "# Y=torch.FloatTensor([[1], [1], [1], [0]]).to(device) #NAND\n",
    "# Y=torch.FloatTensor([[0], [1], [1], [1]]).to(device) #OR\n",
    "Y=torch.FloatTensor([[0], [1], [1], [0]]).to(device) #XOR\n",
    "\n",
    "# 단층 퍼셉트론 설계\n",
    "linear1 = nn.Linear(2, 2, bias=True)\n",
    "sigmoid1 = nn.Sigmoid()\n",
    "linear2 = nn.Linear(2, 1, bias=True)\n",
    "sigmoid2 = nn.Sigmoid()\n",
    "model = nn.Sequential(linear1, sigmoid1, linear2, sigmoid2).to(device)\n",
    "\n",
    "# 이진 분류 문제이므로 비용 함수로 크로스엔트로피 함수 사용\n",
    "# nn.BCELoss() - 이진 분류에서 사용하는 크로스엔트로피 함수\n",
    "\n",
    "# 비용 함수와 옵티마이저 정의\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "#반복학습수행\n",
    "for step in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    \n",
    "    #비용함수\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    " \n",
    "    if step % 100 == 0:  # 100번째 에포크마다 비용 출력\n",
    "        print(step, cost.item())\n",
    "        \n",
    "print('\\n\\n')\n",
    "print('hypothesis값 : ')\n",
    "print(hypothesis)\n",
    "\n",
    "print('\\n')\n",
    "predicted = (hypothesis > 0.5).float()\n",
    "print('예측값 : ')\n",
    "print(predicted)\n",
    "\n",
    "print('\\n')\n",
    "print('실제값 : ')\n",
    "print(Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
